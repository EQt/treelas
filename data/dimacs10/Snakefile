# https://www.cc.gatech.edu/dimacs10/archive/streets.shtml
import h5py
import numpy as np
from numba import njit
from pandas import read_csv
from six.moves.urllib.request import urlretrieve

URL = "https://www.cc.gatech.edu/dimacs10/archive/data/streets"

names = ["asia", "belgium", "europe"]


rule all:
    input: expand("{name}.h5", name=names)


rule download:
    output: "{name}.bz2"
    params: name="{name}"
    run:
        urlretrieve(f"{URL}/{params.name}.osm.graph.bz2", filename=output[0])


@njit(cache=True)
def transform(vals, head, tail, m):
    e = 0
    for i in range(vals.shape[0]):
        for j in range(vals.shape[1]):
            if vals[i,j] < 0:
                break
            if vals[i, j]-1 < i:
                continue
            else:
                if e >= m:
                    return i
                head[e] = i
                tail[e] = vals[i, j] -1
                e += 1
    return -1


rule to_hdf5:
    input: "{name}.bz2"
    output: "{name}.h5"
    run:
        n, m = read_csv(input[0], sep=' ', skiprows=14, nrows=1, header=None).values[0]
        assert n < m, n
        assert m < np.iinfo(np.int32).max, f'{m:,}'

        ncols = 15
        cols = list(range(ncols))
        df = read_csv(input[0], sep=' ', header=None, skiprows=15, names=cols,
                      engine='c', dtype={i: float for i in range(ncols)})
        df[np.isnan(df)] = -1
        df = df.astype(np.int32)

        assert len(df) == n
        assert (df >= 0).astype(int).sum().sum() == 2*m

        for i, j in enumerate(df.max()):
            if j < 0: break

        vals = df.values
        del df

        max_degree = j
        assert max_degree < ncols

        head = -np.ones(m, dtype=np.int32)
        tail = -np.ones(m, dtype=np.int32)
        assert transform(vals, head, tail, m) == -1
        del vals
        assert head.min() >= 0
        assert tail.min() >= 0

        with h5py.File(output[0], 'w') as io:
            g = io
            g.create_dataset("head", data=head, compression=3)
            g.create_dataset("tail", data=tail, compression=3)

