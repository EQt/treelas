# https://www.cc.gatech.edu/dimacs10/archive/streets.shtml
from six.moves.urllib.request import urlretrieve

URL = "https://www.cc.gatech.edu/dimacs10/archive/data/streets"
NAMES = ["asia", "belgium", "europe"]
CMAKE_BUILD = "../../build"


rule all:
    input: expand("{name}.h5", name=NAMES)


rule download:
    output: "{name}.bz2"
    params: name="{name}"
    run:
        urlretrieve(f"{URL}/{params.name}.osm.graph.bz2", filename=output[0])


rule _python_to_hdf5:
    input: "{name}.bz2"
    output: "{name}.py.h5"
    run:
        from convert import convert

        convert(input[0], output[0])


rule julia_bzcat_to_hdf5:
    input: "{name}.bz2"
    output: "{name}.proc.h5"
    shell: "bzcat {input} | julia convert.jl - {output}"


rule julia_to_hdf5:
    input: "{name}.bz2"
    output: "{name}.h5"
    shell: "julia convert.jl {input} {output}"


rule spanning_tree:
    input: "{name}.h5"
    output: "{name}.tree"
    shell: "cp {input} {output} && {CMAKE_BUILD}/traverse {output}"


rule noisy_input:
    input: "{name}.tree"
    output: "{name}.treelas"
    run:
        import numpy as np
        import h5py
        from shutil import copyfile

        np.random.seed(2020)
        copyfile(input[0], output[0])
        with h5py.File(output[0], "r+") as io:
            n = len(io["parent"])
            io.create_dataset("y", data=np.random.randn(n))
            io.create_dataset("lam", data=[0.1])
