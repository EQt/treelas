from os import path
from typing import List


if path.exists("./config.yml"):
    configfile: "./config.yml"
elif path.exists("../config.yml"):
    configfile: "../config.yml"


CMAKE_BUILD = config["cmake_dir"]
PARAMS = dict(s=range(config['num_span_trees']),
              l=config["lam"],
              i=config['num_repetitions'],
              alg=["opt", "apx"])
MAX_ITER = config['apx_max_iter']


def cmake(exe):
    return f"{CMAKE_BUILD}/{exe}"


subworkflow dimacs:
    workdir: "dimacs10"
    configfile: "./config.yml"


subworkflow snap:
    workdir: "snap"
    configfile: "./config.yml"


subworkflow random:
    workdir: "random"
    configfile: "./config.yml"


subworkflow image:
    workdir: "image"
    configfile: "./config.yml"


rule all_degs:
    input:
        random("binary_n1e8.degs"),
        random("randmix_n5e7_f1e-7.degs"),
        image("phantom_w1000.degs"),
        dimacs("europe.degs"),
        snap("com-orkut.degs"),


rule all:
    input:
        random("binary_n1e8.tsv"),
        random("randmix_n5e7_f1e-7.tsv"),
        image("phantom_w1000.tsv"),
        dimacs("europe.tsv"),
        snap("com-orkut.tsv"),


rule cmake_init:
    output: CMAKE_BUILD + "/CMakeCache.txt"
    shell:  "cd {CMAKE_BUILD} && cmake -DCMAKE_BUILD_TYPE=Release .."


rule cmake_build:
    input:  rules.cmake_init.output
    output: cmake("{bin}")
    shell:
        "cmake --build {CMAKE_BUILD} -j{workflow.cores} --target {wildcards.bin}"


rule graph_degrees:
    input:  "{name}_0.tree"
    output: "{name}.degs"
    run:
        from degrees import print_deg_stats

        with open(output[0], "w") as io:
            print_deg_stats(input[0], out=io)


def tsv_concat(output: str, fnames: List[str], sep : str ='\t'):
    """
    Read tab separated values (TSV) from the files as `fnames`
    and make one big tables out of it, to be stored at `output`.
    """
    import pandas as pd

    pd.concat([pd.read_csv(f, sep=sep) for f in fnames])\
      .to_csv(output, sep=sep, index=None)


rule collect_times:
    input: expand("{{name}}_{s}_lam{l}_rep{i}.tree_{alg}.times", **PARAMS)
    output: "{name}.tsv"
    run: tsv_concat(output[0], input)


rule extract_times:
    input:  "{name}_{s}_lam{l}_rep{i}.tree_{alg}"
    output: "{name}_{s}_lam{l}_rep{i}.tree_{alg}.times"
    run:
        import pandas as pd
        from extract_times import extract_time_n

        time_pn, n = extract_time_n(input[0])
        df = pd.DataFrame(data=dict(
            dataset=wildcards.name.rpartition('/')[-1],
            seed=wildcards.s,
            lam=wildcards.l,
            rep=wildcards.i,
            algorithm=f'tree_{wildcards.alg}',
            num_nodes=n,
            time_per_node=time_pn,
        ), index=[0])
        df.to_csv(output[0], sep="\t", index=None)


rule bench_dimacs:
    input:
        dimacs(expand("belgium_{s}_lam{l}_rep{i}.tree_{alg}", **PARAMS))


rule run_treelas:
    input:  "{name}.treelas", cmake("tree_solve")
    output: "{name}_lam{lam}{ignore,(_.*)?}.tree_opti", "{name}_lam{lam,}{ignore,(_.*)?}.tree_sol"
    shell:  "{input[1]} -l {wildcards.lam} {input[0]} | tee {output[0]} && cp {input[0]} {output[1]}"


rule run_treelas_no_output:
    input:  "{name}.treelas", cmake("tree_solve")
    output: "{name}_lam{lam,[^_]+}{ignore,(_.*)?}.tree_opt"
    shell:  "{input[1]} -O -l {wildcards.lam} {input[0]} | tee {output}"


rule run_treeapx:
    input:  "{name}.treelas", cmake("tree_apx")
    output: "{name}_lam{lam,[^_]+}{ignore,(_.*)?}.tree_apx"
    shell:  "{input[1]} -i {MAX_ITER} -l {wildcards.lam} {input[0]} | tee {output}"


rule spanning_tree:
    input:  "{name}.h5", cmake("traverse")
    output: "{name}_{seed,\\d+}.tree"
    shell:  "{input[1]} -s {wildcards.seed} {input[0]} {output}"


rule noisy_input:
    input: "{name}{seed}.tree"
    output: "{name}{seed,_\\d+}.treelas"
    run:
        import numpy as np
        import h5py
        from shutil import copyfile

        seed = wildcards.seed
        seed = int(seed[1:]) if seed[0] == "_" else 2020
        np.random.seed()
        copyfile(input[0], output[0])
        y = None
        img_fn = f"{wildcards.name}.img"
        if path.exists(img_fn):
            with h5py.File(img_fn, "r") as io:
                y = io['y'][:]
        with h5py.File(output[0], "r+") as io:
            n = len(io["parent"])
            if y is None:
                y = np.random.randn(n)
            io.create_dataset("y", data=y)
            io.create_dataset("lam", data=[0.1])
